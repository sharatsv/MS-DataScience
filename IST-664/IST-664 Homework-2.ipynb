{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[The Tragedie of Julius Caesar by William Shakespe\n",
      "[The Tragedie of Hamlet by William Shakespeare 159\n"
     ]
    }
   ],
   "source": [
    "# HW-2 \n",
    "# Exploratory exercise for sentiment analysis\n",
    "# Finding adverb and adjective phrases, and computing basic statistics\n",
    "\n",
    "# importing required nltk libraries\n",
    "import nltk\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "# In HW-1, I used books written by Shakespeare - Caesar and Hamlet. We will continue exploratory \n",
    "# sentiment analysis on the same books\n",
    "nltk.corpus.gutenberg.fileids()\n",
    "\n",
    "# Get Shakespeare books in the Gutenberh corpus\n",
    "shakespeare_books = [book for book in nltk.corpus.gutenberg.fileids( ) \\\n",
    "                     if 'shakespeare' in book]\n",
    "\n",
    "# Book-1: Caesar (Genre: Tragedy)\n",
    "caesar = nltk.corpus.gutenberg.raw(shakespeare_books[0])\n",
    "\n",
    "# Book-2: Hamlet (Genre: Tragedy/Comedy)\n",
    "hamlet = nltk.corpus.gutenberg.raw(shakespeare_books[1])\n",
    "\n",
    "print(caesar[:50])\n",
    "print(hamlet[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[The Tragedie of Julius Caesar by William Shakespeare 1599]\\n\\n\\nActus Primus.', 'Scoena Prima.', 'Enter Flauius, Murellus, and certaine Commoners ouer the Stage.', 'Flauius.', 'Hence: home you idle Creatures, get you home:\\nIs this a Holiday?', 'What, know you not\\n(Being Mechanicall) you ought not walke\\nVpon a labouring day, without the signe\\nOf your Profession?', 'Speake, what Trade art thou?', 'Car.', 'Why Sir, a Carpenter\\n\\n   Mur.', 'Where is thy Leather Apron, and thy Rule?']\n",
      "['[The Tragedie of Hamlet by William Shakespeare 1599]\\n\\n\\nActus Primus.', 'Scoena Prima.', 'Enter Barnardo and Francisco two Centinels.', 'Barnardo.', \"Who's there?\", 'Fran.', 'Nay answer me: Stand & vnfold\\nyour selfe\\n\\n   Bar.', 'Long liue the King\\n\\n   Fran.', 'Barnardo?', 'Bar.']\n"
     ]
    }
   ],
   "source": [
    "# Separate the text into sentences first\n",
    "caesar_split = nltk.sent_tokenize(caesar)\n",
    "print(caesar_split[:10])\n",
    "\n",
    "hamlet_split = nltk.sent_tokenize(hamlet)\n",
    "print(hamlet_split[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['[', 'The', 'Tragedie', 'of', 'Julius', 'Caesar', 'by', 'William', 'Shakespeare', '1599', ']', 'Actus', 'Primus', '.'], ['Scoena', 'Prima', '.']]\n",
      "Type <class 'list'>\n",
      "Caesar tokens: 1592\n",
      "[['[', 'The', 'Tragedie', 'of', 'Hamlet', 'by', 'William', 'Shakespeare', '1599', ']', 'Actus', 'Primus', '.'], ['Scoena', 'Prima', '.']]\n",
      "Hamlet tokens: 2355\n"
     ]
    }
   ],
   "source": [
    "# Apply the word tokenizer to each sentence\n",
    "token_caesar = [nltk.word_tokenize(sent) for sent in caesar_split]\n",
    "print(token_caesar[:2])\n",
    "\n",
    "# the output is a list of strings that contains the sentences\n",
    "print('Type %s' %(type(token_caesar)))\n",
    "print('Caesar tokens: %d' %(len(token_caesar)))\n",
    "\n",
    "# Repeat the same for hamlet text\n",
    "token_hamlet = [nltk.word_tokenize(sent) for sent in hamlet_split]\n",
    "print(token_hamlet[:2])\n",
    "print('Hamlet tokens: %d' %(len(token_hamlet)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('[', 'IN'), ('The', 'DT'), ('Tragedie', 'NNP'), ('of', 'IN'), ('Julius', 'NNP'), ('Caesar', 'NNP'), ('by', 'IN'), ('William', 'NNP'), ('Shakespeare', 'NNP'), ('1599', 'CD'), (']', 'NNP'), ('Actus', 'NNP'), ('Primus', 'NNP'), ('.', '.')], [('Scoena', 'NNP'), ('Prima', 'NNP'), ('.', '.')]]\n",
      "[[('[', 'IN'), ('The', 'DT'), ('Tragedie', 'NNP'), ('of', 'IN'), ('Hamlet', 'NNP'), ('by', 'IN'), ('William', 'NNP'), ('Shakespeare', 'NNP'), ('1599', 'CD'), (']', 'NNP'), ('Actus', 'NNP'), ('Primus', 'NNP'), ('.', '.')], [('Scoena', 'NNP'), ('Prima', 'NNP'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "## POS Tagging, to retrieve adjective (JJs) and adverb (RBs) tags\n",
    "\n",
    "# use the Stanford POS tagger to POS tag tokens of each sentence\n",
    "# this is the default tagger in nltk\n",
    "caesar_tagged = [nltk.pos_tag(tokens) for tokens in token_caesar]\n",
    "print(caesar_tagged[:2])\n",
    "\n",
    "hamlet_tagged = [nltk.pos_tag(tokens) for tokens in token_hamlet]\n",
    "print(hamlet_tagged[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 adjective phrases (Caesar): ['Truly sir ', 'Truly sir ', 'then senslesse ', 'there haue ', 'most exalted ', 'not mou ', 'yet againe ', 'once againe ', 'too stubborne ', 'too strange ']\n",
      "Top adjective phrases by frequency (Caesar): \n",
      "so much  7\n",
      "too much  4\n",
      "so great  3\n",
      "then thy  3\n",
      "so good  3\n",
      "Truly sir  2\n",
      "so many  2\n",
      "most Noble  2\n",
      "more worthy  2\n",
      "not backe  2\n",
      "not meete  2\n",
      "not so haue  2\n",
      "so strong  2\n",
      "then senslesse  1\n",
      "there haue  1\n",
      "most exalted  1\n",
      "not mou  1\n",
      "yet againe  1\n",
      "once againe  1\n",
      "too stubborne  1\n",
      "too strange  1\n",
      "not deceiu  1\n",
      "very much  1\n",
      "Therefore good  1\n",
      "not iealous  1\n",
      "thus much  1\n",
      "not dangerous  1\n",
      "well giuen  1\n",
      "very dangerous  1\n",
      "so sad  1\n",
      "then other  1\n",
      "very loath  1\n",
      "so hee  1\n",
      "thus sad  1\n",
      "so firme  1\n",
      "too sawcie  1\n",
      "Not sensible  1\n",
      "very pleasing  1\n",
      "most mightie  1\n",
      "yet prodigious  1\n",
      "most strong  1\n",
      "So euery  1\n",
      "so bestow  1\n",
      "thus seal  1\n",
      "too bold  1\n",
      "Then secret  1\n",
      "very strong  1\n",
      "not fit  1\n",
      "not meet  1\n",
      "so well belou  1\n",
      "Length of adjective phrase sentences (Caesar): 143\n",
      "---------\n",
      "First 10 adjective phrases (Hamlet): ['now strook ', 'once againe ', 'So frown ', 'most obseruant ', 'most emulate ', 'So hallow ', 'so gracious ', 'So haue ', 'so farre ', 'not fayl ']\n",
      "Top adjective phrases by frequency (Hamlet): \n",
      "so farre  5\n",
      "too much  3\n",
      "as much  3\n",
      "too blame  3\n",
      "So much  2\n",
      "not thy  2\n",
      "not fit  2\n",
      "so much  2\n",
      "most excellent  2\n",
      "not strange  2\n",
      "too heauy  2\n",
      "'Twere good  2\n",
      "not himselfe  2\n",
      "too late  2\n",
      "now strook  1\n",
      "once againe  1\n",
      "So frown  1\n",
      "most obseruant  1\n",
      "most emulate  1\n",
      "So hallow  1\n",
      "so gracious  1\n",
      "So haue  1\n",
      "not fayl  1\n",
      "most valiant  1\n",
      "not more Natiue  1\n",
      "so particular  1\n",
      "vnmanly greefe  1\n",
      "as common  1\n",
      "most vulgar  1\n",
      "most immediate  1\n",
      "most retrograde  1\n",
      "too too solid  1\n",
      "So excellent  1\n",
      "very glad  1\n",
      "very strange  1\n",
      "very pale  1\n",
      "not sleepe  1\n",
      "not permanent  1\n",
      "too credent  1\n",
      "not calumnious  1\n",
      "most imminent  1\n",
      "not dull  1\n",
      "Costly thy  1\n",
      "not exprest  1\n",
      "not gawdie  1\n",
      "most select  1\n",
      "humbly doe  1\n",
      "very oft  1\n",
      "most free  1\n",
      "so tis  1\n",
      "Length of adjective phrase sentences (Hamlet): 237\n"
     ]
    }
   ],
   "source": [
    "# Following our NLTK textbook, chapter on Information Extraction--Chunking (https://www.nltk.org/book/ch07.html)\n",
    "\n",
    "# Using CHUNKING to parse sentences \n",
    "# to look for \"adjective phrases\", i.e. phrases (or chunks) that have adverbs and adjectives ('RB'+'JJ')\n",
    "# First step: writing a grammar that defines the POS in the chunk\n",
    "# we name this grammar \"ADJPH\" (\"ADJective PHrase\") using regexes \n",
    "\n",
    "import re\n",
    "\n",
    "def chunking(grammar, taggedtext, metadata):\n",
    "    # Extract the metadata\n",
    "    label = metadata['label']\n",
    "    desc = metadata['desc']\n",
    "    text = metadata['text']\n",
    "    \n",
    "    # Second step: import the nltk parser to process each sentence\n",
    "    chunk_parser = nltk.RegexpParser(grammar)\n",
    "\n",
    "    _tags = []\n",
    "    for sent in taggedtext:\n",
    "        if len(sent) > 0:\n",
    "            tree = chunk_parser.parse(sent)\n",
    "            for subtree in tree.subtrees():\n",
    "                if subtree.label() == label:\n",
    "                    _tags.append(subtree)\n",
    "                \n",
    "    # Visualizing the actual adj/adv phrase\n",
    "    _phrases = []\n",
    "    for sent in _tags:\n",
    "        temp = ''\n",
    "        for w, t in sent:\n",
    "            temp += w+ ' '    \n",
    "        _phrases.append(temp)\n",
    "    \n",
    "    print('First 10 %s phrases (%s): %s' %(desc, text, _phrases[:10]))\n",
    "    \n",
    "    # Following our NLTK textbook, chapter 1 on Language Processing (https://www.nltk.org/book/ch01.html)\n",
    "    # FREQUENCY DISTRIBUTIONS\n",
    "    # Top 50 adjective phrases\n",
    "    _freq = nltk.FreqDist(_phrases)\n",
    "\n",
    "    print('Top %s phrases by frequency (%s): ' %(desc, text))\n",
    "    for word, freq in _freq.most_common(50):\n",
    "        print(word, freq)\n",
    "\n",
    "            \n",
    "    #print the list of our sentences:\n",
    "    print('Length of %s phrase sentences (%s): %d' %(desc, text, len(_tags)))\n",
    "    \n",
    "    return _tags\n",
    "\n",
    "grammar_adjph = \"ADJPH: {<RB.?>+<JJ.?>}\"\n",
    "# This regex reads as: \"find groups (\"< >\") of RBs (adverbs) together with groups of JJs (adjectives), with groups defineds as\n",
    "# RBs with any ending (the \".\" is a placeholder or wildcard for the \"R\" and the \"S\" at the end of RBR and RBS, \n",
    "# while \"?\" indicates \"optional character\" so RB can be found alone as well). Same regex operators apply to JJs.\n",
    "\n",
    "caesar_adjph_tags = chunking(grammar_adjph, caesar_tagged, {'text':'Caesar', 'label':'ADJPH', 'desc':'adjective'})\n",
    "print('---------')\n",
    "hamlet_adjph_tags = chunking(grammar_adjph, hamlet_tagged, {'text':'Hamlet', 'label':'ADJPH', 'desc':'adjective'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 adverb phrases (Caesar): ['art not ', 'So well ', 'heere so long ', 'as well ', 'as well ', 'so indeed ', 'till now ', 'not so ', 'So soone ', 'not then ']\n",
      "Top adverb phrases by frequency (Caesar): \n",
      "not so  9\n",
      "not well  4\n",
      "as well  3\n",
      "heere so  3\n",
      "So well  2\n",
      "art not  1\n",
      "heere so long  1\n",
      "so indeed  1\n",
      "till now  1\n",
      "So soone  1\n",
      "not then  1\n",
      "not laugh  1\n",
      "so conioyntly  1\n",
      "right well  1\n",
      "so soundly  1\n",
      "so much  1\n",
      "beene often  1\n",
      "directly heere  1\n",
      "so well  1\n",
      "not Wrathfully  1\n",
      "faile not then  1\n",
      "too impatiently  1\n",
      "too much  1\n",
      "not sicke  1\n",
      "so farre  1\n",
      "so earely too  1\n",
      "so neere  1\n",
      "marke well  1\n",
      "not yet  1\n",
      "not fond  1\n",
      "fast together  1\n",
      "yet vnknowne  1\n",
      "So often  1\n",
      "so lowe  1\n",
      "thee well  1\n",
      "Though now  1\n",
      "as fast  1\n",
      "heere lye  1\n",
      "'Twere best  1\n",
      "so poore  1\n",
      "so vnkindely  1\n",
      "doth therefore  1\n",
      "not thus  1\n",
      "durst not  1\n",
      "then yee  1\n",
      "as much  1\n",
      "better then  1\n",
      "very wisely  1\n",
      "well aueng  1\n",
      "not dye  1\n",
      "Length of adverb phrase sentences (Caesar): 74\n",
      "---------\n",
      "First 10 adverb phrases (Hamlet): ['spoke too ', 'Thus twice before ', 'doth well ', 'Thus much ', 'Not so ', 'too too ', 'not so much ', 'too roughly ', 'not well ', 'else neere ']\n",
      "Top adverb phrases by frequency (Hamlet): \n",
      "not so  5\n",
      "not well  4\n",
      "thee well  2\n",
      "very well  2\n",
      "So much  2\n",
      "too much  2\n",
      "so well  2\n",
      "spoke too  1\n",
      "Thus twice before  1\n",
      "doth well  1\n",
      "Thus much  1\n",
      "Not so  1\n",
      "too too  1\n",
      "not so much  1\n",
      "too roughly  1\n",
      "else neere  1\n",
      "too long  1\n",
      "not then  1\n",
      "so cleerely  1\n",
      "so much  1\n",
      "very cold  1\n",
      "natiue heere  1\n",
      "So horridly  1\n",
      "So art  1\n",
      "thou poore  1\n",
      "so helpe  1\n",
      "so ere  1\n",
      "so poore  1\n",
      "so ranke  1\n",
      "so quaintly  1\n",
      "beene so  1\n",
      "thus o  1\n",
      "vs well  1\n",
      "very neere  1\n",
      "euen poore  1\n",
      "not craft enough  1\n",
      "so heauenly  1\n",
      "no longer then  1\n",
      "not better  1\n",
      "not yet  1\n",
      "so indeed  1\n",
      "Very well  1\n",
      "amaze indeed  1\n",
      "so bestow  1\n",
      "right well  1\n",
      "well enough  1\n",
      "quickly too  1\n",
      "not too  1\n",
      "so abhominably  1\n",
      "So long  1\n",
      "Length of adverb phrase sentences (Hamlet): 84\n"
     ]
    }
   ],
   "source": [
    "# Now we look for \"adverb phrases\" or chunks that have 2 consecutive adverbs ('RB')\n",
    "# First step: writing a grammar that defines POS rules of the adverb phrase the chunk\n",
    "# we name this grammar \"ADVPH\" (\"ADVerb PHrase\")\n",
    "grammar_advph = \"ADVPH: {<RB>+<RB>}\"\n",
    "\n",
    "caesar_advph_tags = chunking(grammar_advph, caesar_tagged, {'text':'Caesar', 'label':'ADVPH', 'desc':'adverb'})\n",
    "print('---------')\n",
    "hamlet_advph_tags = chunking(grammar_advph, hamlet_tagged, {'text':'Hamlet', 'label':'ADVPH', 'desc':'adverb'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 50 Adjective tokens:\n",
      "good 48\n",
      "thy 41\n",
      "Noble 32\n",
      "great 25\n",
      "thou 24\n",
      "such 23\n",
      "much 22\n",
      "true 18\n",
      "Good 18\n",
      "many 15\n",
      "dead 14\n",
      "other 13\n",
      "thee 13\n",
      "bad 12\n",
      "best 10\n",
      "mine 10\n",
      "better 10\n",
      "full 10\n",
      "strong 10\n",
      "most 10\n",
      "common 9\n",
      "sure 9\n",
      "wrong 9\n",
      "more 8\n",
      "strange 8\n",
      "worthy 8\n",
      "dangerous 8\n",
      "last 8\n",
      "Most 8\n",
      "Honourable 8\n",
      "hard 7\n",
      "haue 7\n",
      "vs 7\n",
      "gentle 7\n",
      "Such 7\n",
      "same 6\n",
      "high 6\n",
      "owne 6\n",
      "euery 6\n",
      "old 5\n",
      "angry 5\n",
      "sicke 5\n",
      "first 5\n",
      "welcome 5\n",
      "bloody 5\n",
      "mou 4\n",
      "againe 4\n",
      "new 4\n",
      "free 4\n",
      "feeble 4\n",
      "----\n",
      "good 76\n",
      "thy 54\n",
      "more 37\n",
      "such 34\n",
      "most 30\n",
      "much 25\n",
      "dead 25\n",
      "true 21\n",
      "Good 21\n",
      "thou 20\n",
      "great 19\n",
      "owne 18\n",
      "old 16\n",
      "other 15\n",
      "sweet 15\n",
      "mine 15\n",
      "many 15\n",
      "same 13\n",
      "Most 12\n",
      "deere 12\n",
      "Noble 12\n",
      "mad 12\n",
      "Other 12\n",
      "thee 11\n",
      "last 11\n",
      "farre 10\n",
      "first 10\n",
      "little 10\n",
      "second 10\n",
      "selfe 9\n",
      "seene 9\n",
      "strange 9\n",
      "young 9\n",
      "full 9\n",
      "late 9\n",
      "excellent 9\n",
      "free 9\n",
      "welcome 8\n",
      "haue 8\n",
      "heere 8\n",
      "whole 8\n",
      "better 8\n",
      "common 8\n",
      "best 8\n",
      "vs 8\n",
      "fine 8\n",
      "againe 7\n",
      "oft 7\n",
      "long 7\n",
      "bad 7\n"
     ]
    }
   ],
   "source": [
    "# Top 50 tokens (grouped by Adjective, Adverb or Nouns)\n",
    "\n",
    "def top_tokens(taggedtext, pos_list):\n",
    "    _tokens = []\n",
    "    for sentence in taggedtext:\n",
    "        for word, pos in sentence:\n",
    "            if pos in pos_list: \n",
    "                if len(word)>1:\n",
    "                    _tokens.append(word)\n",
    "    freq_pos = nltk.FreqDist(_tokens)\n",
    "\n",
    "    for word, freq in freq_pos.most_common(50):\n",
    "        print(word,freq)\n",
    "\n",
    "# Top 50 adjective tokens\n",
    "print('Top 50 Adjective tokens:')\n",
    "top_tokens(caesar_tagged, ['JJ', 'JJR', 'JJS'])\n",
    "print('----')\n",
    "top_tokens(hamlet_tagged, ['JJ', 'JJR', 'JJS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 50 Adverb tokens:\n",
      "not 255\n",
      "so 103\n",
      "then 79\n",
      "well 40\n",
      "now 39\n",
      "too 30\n",
      "Then 28\n",
      "yet 27\n",
      "heere 26\n",
      "So 24\n",
      "more 24\n",
      "Now 24\n",
      "there 15\n",
      "once 13\n",
      "thus 13\n",
      "else 12\n",
      "very 12\n",
      "away 12\n",
      "still 11\n",
      "as 11\n",
      "most 9\n",
      "directly 8\n",
      "Not 8\n",
      "rather 8\n",
      "onely 7\n",
      "indeed 6\n",
      "alone 6\n",
      "together 6\n",
      "enough 6\n",
      "Yet 6\n",
      "much 6\n",
      "first 6\n",
      "hence 6\n",
      "Well 5\n",
      "Enter 5\n",
      "Therefore 4\n",
      "long 4\n",
      "therefore 4\n",
      "almost 4\n",
      "downe 4\n",
      "here 4\n",
      "neere 4\n",
      "presently 4\n",
      "wisely 4\n",
      "yong 4\n",
      "Truly 3\n",
      "wherefore 3\n",
      "sayes 3\n",
      "Indeed 3\n",
      "yee 3\n",
      "-----\n",
      "not 313\n",
      "so 139\n",
      "then 75\n",
      "now 68\n",
      "well 53\n",
      "too 50\n",
      "more 46\n",
      "very 44\n",
      "most 35\n",
      "So 33\n",
      "Then 33\n",
      "thus 33\n",
      "Now 24\n",
      "yet 23\n",
      "heere 21\n",
      "there 20\n",
      "n't 20\n",
      "away 19\n",
      "indeed 18\n",
      "as 18\n",
      "once 17\n",
      "much 16\n",
      "Not 14\n",
      "still 14\n",
      "else 13\n",
      "Well 9\n",
      "Indeed 9\n",
      "alone 8\n",
      "long 7\n",
      "together 7\n",
      "therefore 7\n",
      "neuer 7\n",
      "better 7\n",
      "Thus 6\n",
      "further 6\n",
      "ere 6\n",
      "enough 6\n",
      "neere 6\n",
      "here 6\n",
      "almost 6\n",
      "first 6\n",
      "freely 5\n",
      "poore 5\n",
      "thee 5\n",
      "presently 5\n",
      "twice 4\n",
      "sometimes 4\n",
      "Therefore 4\n",
      "truly 4\n",
      "longer 4\n"
     ]
    }
   ],
   "source": [
    "# Top 50 adverb tokens\n",
    "print('Top 50 Adverb tokens:')\n",
    "top_tokens(caesar_tagged, ['RB', 'RBR', 'RBS'])\n",
    "print('-----')\n",
    "top_tokens(hamlet_tagged, ['RB', 'RBR', 'RBS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 50 Noun tokens:\n",
      "Caesar 187\n",
      "Brutus 160\n",
      "Bru 152\n",
      "Cassi 107\n",
      "Cassius 85\n",
      "Antony 75\n",
      "Enter 58\n",
      "men 57\n",
      "man 54\n",
      "thou 49\n",
      "Ant 48\n",
      "Lord 44\n",
      "day 41\n",
      "Caesars 38\n",
      "Caes 38\n",
      "Cask 38\n",
      "Rome 37\n",
      "Brut 37\n",
      "selfe 33\n",
      "vs 33\n",
      "Caska 33\n",
      "'d 28\n",
      "Luc 28\n",
      "Will 26\n",
      "hand 26\n",
      "death 26\n",
      "Cinna 26\n",
      "Lucius 26\n",
      "thee 25\n",
      "Messala 25\n",
      "time 24\n",
      "Gods 24\n",
      "Friends 23\n",
      "Titinius 23\n",
      "Exeunt 22\n",
      "Which 22\n",
      "Octauius 22\n",
      "Cas 21\n",
      "Come 21\n",
      "night 21\n",
      "word 20\n",
      "Messa 19\n",
      "haue 18\n",
      "Haue 18\n",
      "blood 18\n",
      "Romans 18\n",
      "thing 18\n",
      "heart 18\n",
      "Octa 18\n",
      "Sir 17\n",
      "----\n",
      "Ham 334\n",
      "Lord 210\n",
      "King 170\n",
      "Hamlet 98\n",
      "Hor 95\n",
      "Enter 80\n",
      "Qu 62\n",
      "Laer 59\n",
      "Ile 58\n",
      "Ophe 55\n",
      "Pol 48\n",
      "Sir 47\n",
      "Father 45\n",
      "thou 43\n",
      "Rosin 43\n",
      "man 42\n",
      "Horatio 40\n",
      "vs 40\n",
      "Queene 39\n",
      "Polon 38\n",
      "time 37\n",
      "Mother 37\n",
      "Heauen 36\n",
      "death 36\n",
      "thee 34\n",
      "selfe 34\n",
      "Mar 31\n",
      "life 30\n",
      "night 29\n",
      "loue 29\n",
      "Clo 29\n",
      "'d 28\n",
      "Ophelia 28\n",
      "hath 26\n",
      "Laertes 26\n",
      "Come 26\n",
      "Nay 25\n",
      "God 25\n",
      "heart 24\n",
      "thing 24\n",
      "matter 24\n",
      "nothing 23\n",
      "vp 23\n",
      "Exeunt 23\n",
      "againe 22\n",
      "world 22\n",
      "Play 22\n",
      "Ghost 21\n",
      "day 21\n",
      "Denmarke 20\n",
      "\n",
      "Top 50 Verb tokens:\n",
      "is 247\n",
      "be 132\n",
      "do 107\n",
      "haue 100\n",
      "are 96\n",
      "was 64\n",
      "know 63\n",
      "did 61\n",
      "am 52\n",
      "let 41\n",
      "come 38\n",
      "were 34\n",
      "say 33\n",
      "see 33\n",
      "tell 31\n",
      "go 30\n",
      "heare 25\n",
      "speake 24\n",
      "make 23\n",
      "Let 23\n",
      "had 23\n",
      "'s 21\n",
      "giue 20\n",
      "take 20\n",
      "Is 19\n",
      "thou 19\n",
      "stand 18\n",
      "feare 17\n",
      "finde 16\n",
      "thinke 16\n",
      "loue 16\n",
      "beare 15\n",
      "thee 14\n",
      "follow 13\n",
      "comes 13\n",
      "doth 13\n",
      "looke 13\n",
      "put 12\n",
      "fell 12\n",
      "leaue 11\n",
      "till 10\n",
      "hath 10\n",
      "bid 10\n",
      "stay 10\n",
      "dye 10\n",
      "keepe 9\n",
      "doe 9\n",
      "send 9\n",
      "wrong 9\n",
      "get 8\n",
      "----\n",
      "is 349\n",
      "be 175\n",
      "haue 129\n",
      "are 111\n",
      "do 79\n",
      "was 79\n",
      "know 66\n",
      "'s 65\n",
      "let 59\n",
      "come 50\n",
      "am 50\n",
      "did 50\n",
      "make 44\n",
      "say 42\n",
      "see 42\n",
      "Let 40\n",
      "tell 39\n",
      "had 37\n",
      "speake 37\n",
      "go 35\n",
      "doe 34\n",
      "thinke 29\n",
      "giue 27\n",
      "were 24\n",
      "comes 22\n",
      "take 21\n",
      "Is 20\n",
      "hold 20\n",
      "hath 19\n",
      "heare 18\n",
      "selfe 18\n",
      "pray 17\n",
      "does 17\n",
      "call 17\n",
      "put 17\n",
      "thou 15\n",
      "set 15\n",
      "thy 14\n",
      "'re 14\n",
      "makes 14\n",
      "made 13\n",
      "Do 13\n",
      "bee 13\n",
      "keepe 13\n",
      "follow 13\n",
      "said 13\n",
      "goes 12\n",
      "finde 12\n",
      "play 12\n",
      "saw 12\n"
     ]
    }
   ],
   "source": [
    "## TO DO / YOUR TURN NOW!\n",
    "## NOUN EXTRACTION\n",
    "## VERB EXTRACTION\n",
    "## REMEMBER TO CHECK THE PENN POS TAGS LIST: https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "## TO FIND ALL TAGS\n",
    "\n",
    "print('Top 50 Noun tokens:')\n",
    "top_tokens(caesar_tagged, ['NN', 'NNS', 'NNP', 'NNPS']) #Noun, Noun-plural, Noun-Proper, Noun-Proper-plural\n",
    "print('----')\n",
    "top_tokens(hamlet_tagged, ['NN', 'NNS', 'NNP', 'NNPS'])\n",
    "\n",
    "\n",
    "print('\\nTop 50 Verb tokens:')\n",
    "top_tokens(caesar_tagged, ['VB', 'VBD', 'VBG', 'VBP', 'VBZ']) # Verb, Verb-past-tense, Verb-present participle,\n",
    "                                                              # Verb-past participle, singular present (non-3rd)\n",
    "                                                              # singular present (3rd)\n",
    "print('----')\n",
    "top_tokens(hamlet_tagged, ['VB', 'VBD', 'VBG', 'VBP', 'VBZ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caeser - adjph/sentences (count): 298\n",
      "Hamlet - adjph/sentences (count): 484\n",
      "Caeser - advph/sentences (count): 151\n",
      "Hamlet - advph/sentences (count): 176\n"
     ]
    }
   ],
   "source": [
    "# Now we have two lists of POS tags combinations we can compare\n",
    "# We need to get the sentences back from the tagging exercise and run some stats\n",
    "\n",
    "def get_len_sent(_tags):\n",
    "    # Create a list of original sentences from the ADJECTIVE/ADVERB phrase subset:\n",
    "    _whole_sentences = []\n",
    "\n",
    "    # loop over the sentences in the adjective phrase sentences we created:\n",
    "    for sents in _tags:\n",
    "        temp=''\n",
    "        for (word,tag) in sents:\n",
    "            temp += word+' '\n",
    "            _whole_sentences.append(temp)\n",
    "        \n",
    "    return len(_whole_sentences)\n",
    "\n",
    "# Get stats - like len() of all adjective/adverb phrase words\n",
    "print('Caeser - adjph/sentences (count): %d' %(get_len_sent(caesar_adjph_tags)))\n",
    "print('Hamlet - adjph/sentences (count): %d' %(get_len_sent(hamlet_adjph_tags)))\n",
    "get_len_sent(hamlet_adjph_tags)\n",
    "\n",
    "# Get stats \n",
    "print('Caeser - advph/sentences (count): %d' %(get_len_sent(caesar_advph_tags)))\n",
    "print('Hamlet - advph/sentences (count): %d' %(get_len_sent(hamlet_advph_tags)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average len of sentence (Caesar): 69.16394472361809\n",
      "Average len of sentence (Caesar): 67.78853503184713\n"
     ]
    }
   ],
   "source": [
    "# Following our NLTK textbook, Writing Structural Programs chapter\n",
    "# section on Procedural vs Declarative style (http://www.nltk.org/book_1ed/ch04.html) \n",
    "\n",
    "## CORPUS STATISTICS--SENTENCES LENGTH\n",
    "\n",
    "# Calculating the average length of sentences in the entire corpus\n",
    "# from http://www.nltk.org/book_1ed/ch04.html\n",
    "caesar_total_corpus = sum(len(sent) for sent in caesar_split) \n",
    "print('Average len of sentence (Caesar): %s' %(caesar_total_corpus / len(caesar_split)))\n",
    "\n",
    "hamlet_total_corpus = sum(len(sent) for sent in hamlet_split) \n",
    "print('Average len of sentence (Hamlet): %s' %(hamlet_total_corpus / len(hamlet_split)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
